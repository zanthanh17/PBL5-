# üìä Ph√¢n T√≠ch & ƒê·ªÅ Xu·∫•t T·ªëi ∆Øu H·ªá Th·ªëng Face Attendance

## üîç T·ªïng Quan Hi·ªán Tr·∫°ng

### Client (Raspberry Pi 3B+)
- **Face Detection**: Haar Cascade (ch·∫≠m, CPU-intensive)
- **Embedding**: MobileFaceNet TFLite (192d)
- **Frame Processing**: Skip 1/3 frames, throttle 0.8s
- **Network**: Synchronous requests v·ªõi retry logic
- **Memory**: Copy face crops, kh√¥ng t√°i s·ª≠ d·ª•ng buffers

### Server
- **Recognition**: Centroid-first + KNN fallback
- **Database**: PostgreSQL + pgvector (HNSW index)
- **Caching**: Centroid cache (refresh 60s)
- **Query**: Raw SQL, ch∆∞a d√πng prepared statements

---

## üöÄ ƒê·ªÄ XU·∫§T T·ªêI ∆ØU

### 1. CLIENT SIDE - Face Detection Optimization

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- Haar Cascade ch·∫≠m (~50-100ms tr√™n Pi 3B+)
- Detect to√†n b·ªô frame m·ªói l·∫ßn
- Kh√¥ng c√≥ ROI tracking

#### ‚úÖ Gi·∫£i ph√°p: ROI Tracking + Adaptive Detection

```python
class FaceTracker:
    """Track face position ƒë·ªÉ gi·∫£m detection area"""
    
    def __init__(self, decay=0.9, min_confidence=0.3):
        self.last_bbox = None
        self.confidence = 0.0
        self.decay = decay
        self.min_confidence = min_confidence
    
    def update(self, bbox):
        """Update tracked bbox"""
        if bbox:
            self.last_bbox = bbox
            self.confidence = 1.0
        else:
            self.confidence *= self.decay
    
    def get_roi(self, frame_shape, expand=1.5):
        """Get ROI ƒë·ªÉ detect (ch·ªâ detect trong v√πng n√†y)"""
        if self.last_bbox and self.confidence > self.min_confidence:
            x, y, w, h = self.last_bbox
            # Expand ROI
            cx, cy = x + w//2, y + h//2
            new_w, new_h = int(w * expand), int(h * expand)
            x1 = max(0, cx - new_w//2)
            y1 = max(0, cy - new_h//2)
            x2 = min(frame_shape[1], cx + new_w//2)
            y2 = min(frame_shape[0], cy + new_h//2)
            return (x1, y1, x2-x1, y2-y1)
        return None

# S·ª≠ d·ª•ng trong main loop:
face_tracker = FaceTracker()
roi = face_tracker.get_roi(gray.shape)
if roi:
    # Ch·ªâ detect trong ROI (nhanh h∆°n 3-5x)
    roi_gray = gray[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]
    faces = face_cascade.detectMultiScale(roi_gray, 1.3, 4, minSize=(60,60))
    # Offset v·ªÅ t·ªça ƒë·ªô g·ªëc
    faces = [(x+roi[0], y+roi[1], w, h) for (x,y,w,h) in faces]
else:
    # Full frame detection (ch·ªâ khi m·∫•t track)
    faces = face_cascade.detectMultiScale(gray, 1.3, 4, minSize=(60,60))
```

**L·ª£i √≠ch**: Gi·∫£m 60-70% th·ªùi gian face detection

---

### 2. CLIENT SIDE - Async Recognition Thread

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- Recognition ch·∫°y trong main loop ‚Üí block camera
- Network request blocking

#### ‚úÖ Gi·∫£i ph√°p: Background Thread v·ªõi Queue

```python
import queue
from threading import Thread

class RecognitionWorker:
    """Background worker ƒë·ªÉ x·ª≠ l√Ω recognition"""
    
    def __init__(self, api_client, embedder, device_id):
        self.api_client = api_client
        self.embedder = embedder
        self.device_id = device_id
        self.queue = queue.Queue(maxsize=2)  # Buffer 2 frames
        self.result_queue = queue.Queue()
        self.running = False
        self.thread = None
    
    def start(self):
        self.running = True
        self.thread = Thread(target=self._worker, daemon=True)
        self.thread.start()
    
    def add_frame(self, face_crop, quality):
        """Add frame ƒë·ªÉ x·ª≠ l√Ω (non-blocking)"""
        try:
            self.queue.put_nowait((face_crop, quality))
        except queue.Full:
            pass  # Skip n·∫øu queue ƒë·∫ßy
    
    def get_result(self):
        """Get result (non-blocking)"""
        try:
            return self.result_queue.get_nowait()
        except queue.Empty:
            return None
    
    def _worker(self):
        """Worker thread"""
        while self.running:
            try:
                face_crop, quality = self.queue.get(timeout=0.1)
                
                # Compute embedding
                emb = normalize_embedding(self.embedder(face_crop))
                
                # API call
                resp = self.api_client.recognize(
                    self.device_id, emb.tolist(), 
                    liveness=0.9, quality=quality
                )
                
                # Put result
                self.result_queue.put_nowait(resp)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"Recognition worker error: {e}")

# S·ª≠ d·ª•ng:
recognition_worker = RecognitionWorker(api_client, embedder, device_id)
recognition_worker.start()

# Trong main loop:
if target:
    face_crop = bgr[y:y+h, x:x+w].copy()
    quality = calc_quality(face_crop)
    recognition_worker.add_frame(face_crop, quality)  # Non-blocking

# Check result
result = recognition_worker.get_result()
if result:
    # Process result
    pass
```

**L·ª£i √≠ch**: Camera loop kh√¥ng b·ªã block, FPS tƒÉng 20-30%

---

### 3. CLIENT SIDE - Memory Optimization

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- `face_crop.copy()` t·∫°o copy kh√¥ng c·∫ßn thi·∫øt
- Numpy operations kh√¥ng t·ªëi ∆∞u
- Gray conversion m·ªói frame

#### ‚úÖ Gi·∫£i ph√°p: Reuse Buffers + In-place Operations

```python
# Pre-allocate buffers
face_buffer = np.zeros((112, 112, 3), dtype=np.float32)
gray_buffer = None

# Trong main loop:
# 1. Reuse gray buffer
if gray_buffer is None or gray_buffer.shape != bgr.shape[:2]:
    gray_buffer = np.zeros(bgr.shape[:2], dtype=np.uint8)
cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY, dst=gray_buffer)

# 2. Face crop kh√¥ng copy (view)
face_crop = bgr[y:y+h, x:x+w]  # View, kh√¥ng copy

# 3. Preprocessing t·ªëi ∆∞u
def preprocess_optimized(face_crop, output_buffer):
    """Preprocess v·ªõi buffer reuse"""
    # Resize tr·ª±c ti·∫øp v√†o buffer
    cv2.resize(face_crop, (112, 112), output_buffer[:,:,::-1], 
               interpolation=cv2.INTER_AREA)  # INTER_AREA nhanh h∆°n INTER_LINEAR
    # BGR->RGB done trong resize
    return output_buffer
```

**L·ª£i √≠ch**: Gi·∫£m 30-40% memory allocation, gi·∫£m GC pressure

---

### 4. CLIENT SIDE - Quality Calculation Optimization

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- T√≠nh Laplacian variance m·ªói l·∫ßn (ch·∫≠m)
- Convert BGR->Gray m·ªói l·∫ßn

#### ‚úÖ Gi·∫£i ph√°p: Cached Quality + Fast Laplacian

```python
def calc_quality_fast(face_gray: np.ndarray) -> float:
    """Fast quality calculation v·ªõi Sobel thay v√¨ Laplacian"""
    # Brightness (nhanh)
    brightness = float(np.mean(face_gray))
    
    # Sharpness: d√πng Sobel thay v√¨ Laplacian (nhanh h∆°n 2x)
    sobel_x = cv2.Sobel(face_gray, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(face_gray, cv2.CV_64F, 0, 1, ksize=3)
    sharpness = float(np.mean(sobel_x**2 + sobel_y**2))
    
    # Normalize
    b_norm = np.clip((brightness - 50) / (190 - 50), 0, 1)
    s_norm = np.clip((sharpness - 100) / (500 - 100), 0, 1)
    
    return float(0.5 * b_norm + 0.5 * s_norm)

# Ho·∫∑c cache quality n·∫øu face kh√¥ng thay ƒë·ªïi nhi·ªÅu
class QualityCache:
    def __init__(self, threshold=0.1):
        self.last_face_hash = None
        self.last_quality = None
        self.threshold = threshold
    
    def get_quality(self, face_crop):
        # Simple hash (mean of corners)
        h, w = face_crop.shape[:2]
        corners = face_crop[0,0] + face_crop[0,-1] + face_crop[-1,0] + face_crop[-1,-1]
        face_hash = np.mean(corners)
        
        if self.last_face_hash and abs(face_hash - self.last_face_hash) < self.threshold:
            return self.last_quality
        
        self.last_face_hash = face_hash
        self.last_quality = calc_quality_fast(face_crop)
        return self.last_quality
```

**L·ª£i √≠ch**: Gi·∫£m 40-50% th·ªùi gian t√≠nh quality

---

### 5. CLIENT SIDE - Embedding Preprocessing Optimization

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- `cv2.resize` v·ªõi INTER_LINEAR (ch·∫≠m)
- Prewhiten t√≠nh l·∫°i m·ªói l·∫ßn

#### ‚úÖ Gi·∫£i ph√°p: INTER_AREA + Optimized Prewhiten

```python
def preprocess_optimized(bgr_face: np.ndarray, output_buffer: np.ndarray):
    """Optimized preprocessing"""
    # 1. Resize v·ªõi INTER_AREA (nhanh h∆°n, t·ªët cho downscale)
    cv2.resize(bgr_face, (112, 112), output_buffer, 
               interpolation=cv2.INTER_AREA)
    
    # 2. BGR->RGB (in-place)
    output_buffer[:,:,:] = output_buffer[:,:,::-1]
    
    # 3. Prewhiten t·ªëi ∆∞u (vectorized)
    mean = np.mean(output_buffer)
    std = np.std(output_buffer)
    std_adj = max(std, 1.0 / np.sqrt(output_buffer.size))
    output_buffer[:] = (output_buffer - mean) / std_adj
    
    return output_buffer
```

**L·ª£i √≠ch**: Gi·∫£m 20-30% preprocessing time

---

### 6. SERVER SIDE - Centroid Cache v·ªõi In-Memory Matching

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- Query database m·ªói l·∫ßn (d√π c√≥ cache)
- String concatenation cho vector

#### ‚úÖ Gi·∫£i ph√°p: In-Memory Matching

```python
# app/utils/centroid_cache.py - Enhanced
import numpy as np
from typing import Dict, Tuple, Optional

class CentroidCache:
    def __init__(self):
        self._lock = threading.Lock()
        self._centroids = {}  # emp_id -> np.array (192d)
        self._emp_names = {}  # emp_id -> full_name
        self._last_load = 0.0
    
    def load_now(self, db: Session):
        rows = db.execute(text("""
            SELECT ec.emp_id, ec.centroid, e.full_name
            FROM employee_centroids ec
            JOIN employees e ON e.emp_id = ec.emp_id
            WHERE ec.model = :m
        """), {"m": MODEL}).fetchall()
        
        centroids = {}
        names = {}
        for r in rows:
            centroids[r.emp_id] = np.array(list(r.centroid), dtype=np.float32)
            names[r.emp_id] = r.full_name
        
        with self._lock:
            self._centroids = centroids
            self._emp_names = names
            self._last_load = time.time()
    
    def match(self, query_vec: np.ndarray, threshold: float) -> Optional[Tuple[str, str, float]]:
        """Fast in-memory matching"""
        query_vec = query_vec.astype(np.float32)
        query_vec = query_vec / (np.linalg.norm(query_vec) + 1e-12)
        
        best_emp = None
        best_score = 0.0
        
        with self._lock:
            for emp_id, centroid in self._centroids.items():
                # Cosine similarity: dot product (ƒë√£ normalized)
                score = float(np.dot(query_vec, centroid))
                if score > best_score:
                    best_score = score
                    best_emp = emp_id
        
        if best_score >= threshold:
            return (best_emp, self._emp_names.get(best_emp, best_emp), best_score)
        return None

# S·ª≠ d·ª•ng trong recognize.py:
cache.ensure_fresh(db)
result = cache.match(q, TH_CENTROID)
if result:
    emp_id, full_name, score = result
    return {"status": "ok", "result": {...}}
```

**L·ª£i √≠ch**: Gi·∫£m 80-90% latency (kh√¥ng c·∫ßn query DB)

---

### 7. SERVER SIDE - Prepared Statements

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- Raw SQL strings m·ªói l·∫ßn
- Kh√¥ng t√°i s·ª≠ d·ª•ng query plans

#### ‚úÖ Gi·∫£i ph√°p: Prepared Statements

```python
# app/db.py
from sqlalchemy import text

# Prepared statements
PREPARED_STMTS = {}

def get_prepared_stmt(key: str, sql: str):
    """Get or create prepared statement"""
    if key not in PREPARED_STMTS:
        PREPARED_STMTS[key] = text(sql)
    return PREPARED_STMTS[key]

# S·ª≠ d·ª•ng:
KNN_SQL = get_prepared_stmt("knn", """
    SELECT emb.emp_id, e.full_name,
           (1 - (emb.embedding <#> CAST(:qv AS vector(192)))) AS score
    FROM embeddings emb
    JOIN employees e ON e.emp_id = emb.emp_id
    WHERE emb.model = :m
    ORDER BY score DESC
    LIMIT :k
""")

rows = db.execute(KNN_SQL, {"qv": qv, "m": MODEL, "k": K_FALLBACK})
```

**L·ª£i √≠ch**: Gi·∫£m 10-15% query time

---

### 8. SERVER SIDE - Batch Processing cho KNN

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- KNN query m·ªói l·∫ßn (ch·∫≠m v·ªõi nhi·ªÅu embeddings)

#### ‚úÖ Gi·∫£i ph√°p: Adaptive K (gi·∫£m K n·∫øu centroid match t·ªët)

```python
# Trong recognize.py
# N·∫øu centroid score g·∫ßn threshold, ch·ªâ c·∫ßn K nh·ªè h∆°n
if c_row and c_row.score is not None:
    score = float(c_row.score)
    if score >= TH_CENTROID:
        # Match t·ªët, return lu√¥n
        return {...}
    elif score >= TH_CENTROID - 0.1:  # G·∫ßn threshold
        # Ch·ªâ c·∫ßn K nh·ªè
        k = min(3, K_FALLBACK)
    else:
        # C·∫ßn K l·ªõn h∆°n
        k = K_FALLBACK
    
    rows = knn_cosine(db, q.tolist(), k=k, model=MODEL)
```

**L·ª£i √≠ch**: Gi·∫£m 30-50% KNN query time khi centroid g·∫ßn match

---

### 9. CLIENT SIDE - Adaptive Frame Skip

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- Frame skip c·ªë ƒë·ªãnh (3)

#### ‚úÖ Gi·∫£i ph√°p: Adaptive d·ª±a tr√™n CPU load

```python
import psutil

class AdaptiveFrameSkip:
    def __init__(self, base_skip=3, max_skip=5, min_skip=1):
        self.base_skip = base_skip
        self.max_skip = max_skip
        self.min_skip = min_skip
        self.current_skip = base_skip
        self.last_check = time.time()
    
    def get_skip(self):
        # Check CPU m·ªói 2 gi√¢y
        if time.time() - self.last_check > 2.0:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            if cpu_percent > 80:
                self.current_skip = min(self.max_skip, self.current_skip + 1)
            elif cpu_percent < 50:
                self.current_skip = max(self.min_skip, self.current_skip - 1)
            
            self.last_check = time.time()
        
        return self.current_skip

# S·ª≠ d·ª•ng:
adaptive_skip = AdaptiveFrameSkip()
if frame_counter % adaptive_skip.get_skip() != 0:
    continue
```

**L·ª£i √≠ch**: T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh theo CPU load

---

### 10. CLIENT SIDE - Network Compression

#### ‚ùå V·∫•n ƒë·ªÅ hi·ªán t·∫°i:
- G·ª≠i embedding 192 floats m·ªói l·∫ßn (~768 bytes)

#### ‚úÖ Gi·∫£i ph√°p: Quantization + Compression

```python
import struct
import zlib

def compress_embedding(emb: np.ndarray) -> bytes:
    """Compress embedding v·ªõi quantization"""
    # Quantize t·ª´ float32 -> int16 (gi·∫£m 50% size)
    emb_int16 = (emb * 32767).astype(np.int16)
    
    # Pack binary
    packed = struct.pack(f'{len(emb_int16)}h', *emb_int16)
    
    # Compress
    compressed = zlib.compress(packed, level=1)  # level=1 nhanh
    
    return compressed

def decompress_embedding(data: bytes) -> np.ndarray:
    """Decompress embedding"""
    unpacked = zlib.decompress(data)
    emb_int16 = struct.unpack(f'{len(unpacked)//2}h', unpacked)
    emb = np.array(emb_int16, dtype=np.float32) / 32767.0
    return emb

# Server nh·∫≠n compressed embedding
@router.post("/v1/recognize")
def recognize(req: dict, db: Session = Depends(get_db)):
    embedding_data = req.get("embedding_compressed")
    if embedding_data:
        q = decompress_embedding(bytes(embedding_data))
    else:
        # Fallback to uncompressed
        q = np.asarray(req["embedding"], dtype=np.float64)
```

**L·ª£i √≠ch**: Gi·∫£m 60-70% network bandwidth

---

## üìà T·ªïng K·∫øt L·ª£i √çch

| T·ªëi ∆∞u | C·∫£i thi·ªán | ƒê·ªô kh√≥ |
|--------|-----------|--------|
| ROI Tracking | 60-70% face detection | Trung b√¨nh |
| Async Recognition | 20-30% FPS | D·ªÖ |
| Memory Optimization | 30-40% memory | D·ªÖ |
| Quality Fast Calc | 40-50% quality time | D·ªÖ |
| In-Memory Centroid | 80-90% latency | Trung b√¨nh |
| Adaptive Frame Skip | 10-20% CPU | D·ªÖ |
| Network Compression | 60-70% bandwidth | Trung b√¨nh |

---

## üéØ ∆Øu Ti√™n Tri·ªÉn Khai

### Phase 1 (D·ªÖ, Impact cao):
1. ‚úÖ Async Recognition Thread
2. ‚úÖ Memory Optimization
3. ‚úÖ Quality Fast Calculation
4. ‚úÖ Adaptive Frame Skip

### Phase 2 (Trung b√¨nh, Impact r·∫•t cao):
5. ‚úÖ ROI Tracking
6. ‚úÖ In-Memory Centroid Matching
7. ‚úÖ Network Compression

### Phase 3 (N√¢ng cao):
8. ‚úÖ Prepared Statements
9. ‚úÖ Adaptive K for KNN
10. ‚úÖ Advanced preprocessing

---

## üí° L∆∞u √ù

- Test t·ª´ng optimization ri√™ng ƒë·ªÉ ƒëo impact
- Monitor CPU, memory, latency sau m·ªói thay ƒë·ªïi
- Gi·ªØ backward compatibility
- Document c√°c thay ƒë·ªïi

